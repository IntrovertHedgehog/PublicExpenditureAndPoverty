---
title: "Selectively Remove Variables"
author: "Callista Stephine Yu"
date: "2022-11-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(knitr)
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(stats)
library(tidyverse)
library(e1071)
library(car)
library(glmnet)
library(corrplot)
```

```{r}
countries <- read.csv("../data/countries.csv")
```


```{r}
head(countries)
```
This approach takes variables that contain less than 35% of missing data.The previous analysis showed that the relations between the predicted variable and gdp.pc, gdp.dflt, and fdi are better fitted to logarithmic models. Hence, we transformed the data with the mutate() function before building the machine learning model.
```{r}

subset0 <- subset(countries, select = c("country.code", "year","edu.total", "fdi","gcf","gdp.dflt","hlth","income","lbr.part","mil","pop.gwth.rural","pop.gwth.urban","pov","trade", "unemp", "year","gdp.pc" ))

subset1_0 <- subset0 %>% mutate(lfdi = log(subset0$fdi)) %>% mutate(lgdp.pc = log(subset0$gdp.pc)) %>% mutate(lgdp.dflt = log(subset0$gdp.dflt))

```
subset1 contains the variables below 35% of missing values. 
```{r}
subset1 <- subset(subset1_0, select = c("edu.total", "lfdi","gcf","lgdp.dflt","hlth","income","lbr.part","mil","pop.gwth.rural","pop.gwth.urban","pov","trade", "unemp", "year","lgdp.pc"))

subset1 <- na.omit(subset1)
```
We also performed standardisation to reduce the variance of our machine learning models. Below are the functions used to aid our standardisation step. 
```{r}
sd0 <- function(vct) {
  if (!is.numeric(vct)) {
    return(NA)
  }
  
  return(sd(vct, na.rm = T))
}


std0 <- function(vct, scl) {
  if (!is.numeric(vct)) {
    return(vct)
  }
  
  return(vct/scl)
}

scale <- function(data) {
  unlist(lapply(data, sd0))
}

standardise <- function(data) {
  scaler <- scale(data)
  
  numCols <- which(unlist(lapply(data, is.numeric)))
  num <- as.data.frame(mapply(std0, vct = data[,numCols], scl = scaler[numCols], SIMPLIFY = T))
  fct <- data[,-numCols]
  return(cbind(fct, num))
}


```

```{r}

df.countries0 <- standardise(subset1)
df.countries <- df.countries0
```

```{r}
#Divide each feature/target by its standard deviation


head(df.countries)
```

First, we split the data into training and testing data. 
```{r}
set.seed(123)
index <- sort(sample(x = nrow(df.countries), size = nrow(df.countries) * 0.8))
train_1 <- subset1[index,]
test_1 <- subset1[-index,]

```

Our first attempt 
```{r}
#Everything
lm_1 <- lm(data= train_1, formula = pov ~ .)
summary(lm_1)
```
```{r}
#remove hlth 
lm_2 <- lm(data= train_1, formula = pov ~ .-lfdi - lgdp.dflt)
summary(lm_2)
plot(lm_2, which = 5)
```

```{r}
#Remove lgdp.dflt
lm_3 <- lm(data= train_1, formula = pov ~ . -lgdp.dflt)
summary(lm_3)
plot(lm_3, which = 5)
```
```{r}
#remove lfdi
lm_4 <- lm(data= train_1, formula = pov ~ . -hlth - lgdp.dflt - lfdi)
summary(lm_4)
plot(lm_4, which = 5)
```
Our model shows that among all the 13 predictor variables that we started with, only 10 of them showed significance in building the model. 

We then evaluated the results of the model. 
```{r}
#evaluating lm_4
eval.metrics.linreg <- function(actual, predicted) {
  residual <- actual - predicted
  mse <- mean(residual ^ 2)
  mae <- mean(abs(residual))
  rmse <-  sqrt(mse)
  mape <- mean(abs(residual / actual)) * 100
  
  
  data.frame(
    MSE = mse,
    MAE = mae,
    RMSE = rmse,
    MAPE = mape
  )
}
```

```{r}
actual <- train_1$pov
predicted <- predict(lm_4, newdata = train_1)
eval.metrics.linreg(actual, predicted)
```

```{r}
#subsetting df.countries to only contain variables present in lm_7

data0 <- subset(subset1_0, select = c("country.code","year","edu.total", "lfdi","gcf","lgdp.dflt","hlth","income","lbr.part","mil","pop.gwth.rural","pop.gwth.urban","pov","trade", "unemp", "year","lgdp.pc"))
data <- na.omit(data0)
train.x <- data.matrix(subset(data, select = -pov))
train.y <- data.matrix(data$pov)

```

```{r}
#Find the ridge regression model
# set.seed(123)
# rate <- 0.8
# train.size <- round(nrow(data)*rate)
# sample(sample(nrow(data), train.size))
# training <- data[sample, ]
# test <- data[-sample, ]
# 


```

```{r}
split_train_test <- function(data) {
set.seed(1984)
# split data
seeds <- data %>% 
  group_by(country.code) %>% 
  filter(row_number() == 1)

plants <- data %>% 
  group_by(country.code) %>% 
  filter(row_number() != 1)

isComplete <- which(complete.cases(plants))
idx <- sample(isComplete, replace = F, 0.2 * nrow(plants))

training <- plants[-idx,] %>% 
  rbind(seeds)
test <- plants[idx,]

return(list(training, test))
}
```

```{r}
training <- split_train_test(data)[[1]]
test <- split_train_test(data)[[2]]
```

```{r}
ntrain <- 1:nrow(training)
combine <- rbind(training, test)
combine.mtrx <- model.matrix(pov ~ ., data = combine)
train.mtrx <- combine.mtrx[ntrain,]
test.mtrx <- combine.mtrx[-ntrain,]

train.x <- train.mtrx[,-1]
train.y <- training$pov

test.x <- test.mtrx[,-1]
text.y <- test$pov
```


```{r}
cv_ridge <- cv.glmnet(train.x, train.y, alpha = 0)
glm_ridge <- glmnet(train.x, train.y, alpha = 0, lambda = cv_ridge$lambda.min)


t(coef(glm_ridge))
```

```{r}
#generate sequence of lambda values 
lambda <- 10^seq(-6, 2, length = 100)
ridge_model = glmnet(train.x, train.y, alpha = 0, lambda = lambda)

t(coef(ridge_model))
```

```{r}
plot(ridge_model, xvar = "lambda", label = TRUE)

#customise the plot with labels
add_lbs <- function(fit, offset_x = 2.5) {
  L <- length(fit$lambda[L]) + offset_x
  y <- fit$beta[,L]
  labs <- names(y)
  text(x, y , labels = labs, cex = 1.5)
  
  title(main = "Coefficients of Predictors vs Log(Lambda)",cex.main = 1.4, adj = 0, line = 3)
  title(sub = "Number of Predictors", cex.sub = 1.1, adj = 0.55, line = -21.5)
  add_lbs(ridge_model)
  legend("topright", lwd = 1, col = 1:6, legend = colnames(train.x), cex = .7)

}
```

```{r}
plot_glmnet(ridge_model)
```
```{r}
#cross - validation
set.seed(123)
cv_ridge <- cv.glmnet(train.x, train.y, alpha = 0, type.measure = "mse")

```

```{r}
cv_ridge
cv_ridge$lambda.min
cv_ridge$lambda.1se
```


```{r}
plot(cv_ridge)
abline(v=log(cv_ridge$lambda.min), col = "red", lty=5)
text(log(cv_ridge$lambda.min)+1, 1.4, 
     labels= paste0("lambda_min = ", 
                    round(cv_ridge$lambda.min, digits = 3)), 
     cex = 1.1)

# Label for lambda.1se
abline(v=log(cv_ridge$lambda.1se), 
       col = "red", lty=5)
text(log(cv_ridge$lambda.1se)+1, 1.25, 
     labels= paste0("lambda_1se = ", 
                    round(cv_ridge$lambda.1se, digits = 3)), cex = 1.1)

```

```{r}
#train the ridge regression model using lambda.min

glm_Ridge <- glmnet(train.x, train.y, alpha = 0, lambda = cv_ridge$lambda.min)
t(coef(glm_Ridge))
```
```{r}
eval_results <- function(fit, true) {
  actual <- data.matrix(true)
  SSE <- sum((actual - fit)^2)
  SST <- sum((actual - mean(actual))^2)
  R_square <- 1 - SSE/SST
  data.frame(
    MSE = MSE(fit, true),
    MAE = MAE(fit, true),
    RMSE = RMSE(fit, true),
    MAPE = MAPE(fit, true),
    R2  = R_square
    
  )
}
```

```{r}
fit <- predict(glm_Ridge, train.x)
true <- train.y
summary_Ridge_train <- eval_results(fit, true)
summary_Ridge_train
```


```{r}
fit <- predict(glm_Ridge, test.x)
true <- test.y
summary_Ridge_test <- eval_results(fit, true)
summary_Ridge_test
```

```{r}
summary_Ridge <- rbind(summary_Ridge_train[-5], summary_Ridge_test[-5])
rownames(summary_Ridge) <- c("Ridge_train", "Ridge_test")
knitr::kable(summary_Ridge, digits = 3)

```

```{r}
#Obtain fitted and true values

fit <- predict(glm_Ridge, train.x)
true <- train.y

```

```{r}
#Plot residuals s
plot(fit, true - fit, 
     main = "Residual Plot of Ridge Regression Model on the Training dataset",
     xlab = "Fitted value",
     ylab = "Standardised Residuals")
abline(h = 0, col = "red", lwd = 2)
abline(h = 1, col = "red", lty = 2, lwd = 2)
abline(h = -1, col = "red", lty = 2, lwd = 2)

```
Constant varince assumption not satisfied. What to do? Most likely need to transform the variable
TO TRANSFORM TO BOXCOX 

```{r}
#Train a LASSO regression model
set.seed(123)
cv_lasso <- cv.glmnet(train.x, train.y, alpha = 1, type.measure = "mse")
```

```{r}
cv_lasso
```

```{r}
plot(cv_lasso)
```

```{r}
glm_Lasso <- glmnet(train.x, train.y, alpha = 1, lambda = cv_lasso$lambda.min)
t(coef(glm_Lasso))
```

```{r}
fit2 <- predict(glm_Lasso, train.x)
true2 <- train.y
summary_Lasso_train <- eval_results(fit2, true2)
summary_Lasso_train
```

```{r}
fit3 <- predict(glm_Lasso, test.x)
true3 <- test.y
summary_Lasso_test <- eval_results(fit3, true3)
summary_Lasso_test
```

